# TODOs
## For the Ruland lexicon (Ruland1612)

1. **TEI checking:** 
 - Does the TEI make sense according to the [Dictionaries module](https://tei-c.org/release/doc/tei-p5-doc/en/html/DI.html)? It uses elements like `<entry>` (so far, `@type` for which letter in the dictionary and `@n` which should later become `@xml:id`), `<dictScrap>`, `<sense>`, `<def>` (usually for the Latin definition), `<cit>` (usually contains German text in Fraktur) and some others (but many aren't used consistently and data quality gets worse further into the book). Analyse which elements are used and where/when/how often and come up with suggestions for improvement. I indicated which letter each entry belongs to using `@type` so far - how should such information be encoded according to the guidelines? What to do about the segments in Ancient Greek? (related: are they actually there or are those OCR artifacts?). Do we need u/v or i/j normalization?
 - Check `@type='lemma'` that must have been added to all/most entries via regex (this was missing in many cases and I don't think there was a reason for it); TODO the same should probably be done with the attributes indicating German Fraktur snippets (these are missing in the `<cit>` towards the end of the dataset and I also have a feeling there aren't any such elements used for anything other than German snippets, although I might be wrong about this... would need to be checked before replace-all.
 - Consider reintroducing alphabetical indexing (like 'Letter A begins here') by putting [a milestone element](https://tei-c.org/release/doc/tei-p5-doc/en/html/CO.html#CORS5) (most likely `<milestone>`) or similar potentially suitable non-nesting elements in the relevant places (shouldn't take too long). Encoding suggestion: `<milestone unit="letter" n="A"/>`.
2. **Creating IDs:** Create IDs for the entries. This is already happening in part in the `adding-entry-ids-Ruland1612.xsl` (so far adding them as `@n` as this will not disturb validation in case IDs aren't yet unique). After the script is run, these IDs need to be checked (some include junk characters or the same ID appears multiple times) - once they are of high enough quality to work as `@xml:id`, use a regex replacement to turn `<entry @n` to `<entry xml:id`. What can be done here is to run the XSL on the current data and inspect where it produces validation errors in the resulting XML: If plain text ends up in the output, there might be nesting problems with that respective entry in the input. Also, is anything missing from the template? (such as elements on the nesting level of entry beyond `<fw>` and `<pb>` because only those are covered by the transformation so far). Once the transformation works ok and ids have been added, we can continue working with the output file (and make any necessary manual edits there in the output file) - but while the transformation is still buggy, manual fixes should be added to the base file still. See [this example image](https://github.com/sarahalang/alchemical-dictionaries/blob/main/example-entry-nesting-problem.png) (showing the error that happens in the output and would need to be investigated in the input file). The XML file from which this snapshot was taken (an example of what the output looks like when you transform `Ruland.xml` with the XSL `transform-ruland-include-ids.xsl`) is: `adding-entry-ids-ruland1612.xml`.
3. **Create an HTML preview:** for example, a list item (unordered) per entry, with the lemma in bold (`<b>`). The German parts could be rendered in italics (`<i>`). Maybe use `<xsl:for-each>` to add something like `<h1>A</h1>` before the first entry of `@type='A'`, etc. A mini-to-bootstrap XSL that can be used as a base is [here](https://github.com/sarahalang/Harvard_BeyondTEI_Workshop_SLang2022/blob/main/ADDITIONAL_RESOURCES/XSL_BASE_STYLESHEETS/mini-bootstrap.xsl). 
4. **Improve the TEI Header** by adding information from the Noscemus project and documenting how the data were processed. The encoding was begun in summer term 2023 by Ines Lesjak in Uni Graz DH Projektseminar and while this was a great first step, the resulting data quality was inconsistent. Improve the `<div type='frontmatter'>`. See: [NOSCEMUS wiki](https://wiki.uibk.ac.at/noscemus/Lexicon_Alchemiae) for metadata.  
5. **Cross-Referencing:** This dictionary would be a much more interesting resource if there were cross-referencing (many items get mentioned in some entry that have an entry of their own), however, this can only be semi-automated (maybe regex-but-step-through-replace. Also, it might be relevant to encode synonyms - but for that one would need enough Latin (or familiarity with the relatively limited ways this is expressed in Ruland) to make those decisions.
6. **Create RDF/SKOS**(?) from the dictionary using the `@xml:id` of each entry as the concept name, the Latin name version from `<form @type='lemma'>` and the German version from the related encoding (although the German sections aren't consistently labeled throughout the book, especially later in the book and switch between lemma in German and definition in German). Likely, this will only make sense in a quite reduced manner until the data quality is near perfect.
7. **Open Questions:** Are there nested entries? If yes (seems so), how to proceed? How to indicate they are related? (Apart from this added information, it would make sense to encode them separately). 
8. **HTML preview:** Improving the HTML preview (adding enough detail so that all elements are covered and the output is a simple HTML file that people can use). The current version of the XSL runs on the imperfect/error-laden XML output (`HTML-preview/adding-entry-ids-ruland1612.xml`) of the transformation before it (`transform-ruland-include-ids.xsl`): [The folder 'HTML-preview'](https://github.com/sarahalang/alchemical-dictionaries/tree/main/HTML-preview) contains the relevant files (`HTML-preview/ruland-xml-preview.html` is the output of `HTML-preview/visualize-ruland-in-html.xsl`). In the end, it should, of course, be run on the final correct XML data. When running and improving the transformation for the simple HTML preview, one notices a number of errors in the XML, such as likely Transkribus-caused transcription errors in the header lines such as `RVLANDI PHILOS. ET MEDICI ` or `RVLANDI PHIL. Ex MEDICI. `. One could either check if these go back to actual print anomalies and encode them in TEI in a way that makes sense (so that they're encoded as `fw @type='header'` and thus, equally suppressed in the HTML preview.) or just find textual versions of these headers and add `@type='header'` so they get processed as they should. They're not the most central element of the TEI, so fixing them isn't a priority beyond making the transformation to HTML work alright. 
